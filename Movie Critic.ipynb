{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b2361e-1a7c-4982-b2b6-3c739e5ad482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepanshu.kandpal/Library/Caches/pypoetry/virtualenvs/llm-r-8tQ7me-py3.9/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/deepanshu.kandpal/Library/Caches/pypoetry/virtualenvs/llm-r-8tQ7me-py3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34094a98-8bf9-427d-8081-caa93a8f969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/deepanshu.kandpal/Library/Caches/pypoetry/virtualenvs/llm-r-8tQ7me-py3.9/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token: Traceback (most recent call last):\n",
      "  File \"/Users/deepanshu.kandpal/Library/Caches/pypoetry/virtualenvs/llm-r-8tQ7me-py3.9/bin/huggingface-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/deepanshu.kandpal/Library/Caches/pypoetry/virtualenvs/llm-r-8tQ7me-py3.9/lib/python3.9/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 49, in main\n",
      "    service.run()\n",
      "  File \"/Users/deepanshu.kandpal/Library/Caches/pypoetry/virtualenvs/llm-r-8tQ7me-py3.9/lib/python3.9/site-packages/huggingface_hub/commands/user.py\", line 98, in run\n",
      "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
      "  File \"/Users/deepanshu.kandpal/Library/Caches/pypoetry/virtualenvs/llm-r-8tQ7me-py3.9/lib/python3.9/site-packages/huggingface_hub/_login.py\", line 112, in login\n",
      "    interpreter_login(new_session=new_session, write_permission=write_permission)\n",
      "  File \"/Users/deepanshu.kandpal/Library/Caches/pypoetry/virtualenvs/llm-r-8tQ7me-py3.9/lib/python3.9/site-packages/huggingface_hub/_login.py\", line 167, in interpreter_login\n",
      "    token = getpass(\"Token: \")\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/getpass.py\", line 77, in unix_getpass\n",
      "    passwd = _raw_input(prompt, stream, input=input)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/getpass.py\", line 146, in _raw_input\n",
      "    line = input.readline()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cea17cf-98ee-4306-81f5-5e0e4722c613",
   "metadata": {},
   "source": [
    "# Generate dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61566bf-b8fd-4503-82f0-e6a7e7f593cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy dataset saved to film_reviews_dataset.txt\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Dummy dataset generation for film reviews\n",
    "def generate_film_reviews(num_reviews=100, max_review_length=200):\n",
    "    positive_adjectives = [\"amazing\", \"fantastic\", \"captivating\", \"outstanding\", \"excellent\"]\n",
    "    negative_adjectives = [\"disappointing\", \"boring\", \"predictable\", \"mediocre\", \"unimpressive\"]\n",
    "    movies = [\"The Midnight Star\", \"Dreamscape\", \"Eternal Echo\", \"Lost Horizon\", \"Whispering Shadows\"]\n",
    "\n",
    "    reviews = []\n",
    "\n",
    "    for _ in range(num_reviews):\n",
    "        movie = random.choice(movies)\n",
    "        rating = random.randint(1, 10)\n",
    "        adjective = random.choice(positive_adjectives) if rating > 5 else random.choice(negative_adjectives)\n",
    "        review_text = f\"{movie} is {adjective}! I would give it a {rating}/10. \"\n",
    "        review_text += \" \".join([\"This movie\", \"exceeded my expectations.\", \"Highly recommended!\", \"A must-watch!\"] * random.randint(1, 3))\n",
    "        review_text += \"\\n\\n\"\n",
    "\n",
    "        # Trim the review if it exceeds the max length\n",
    "        review_text = review_text[:max_review_length]\n",
    "\n",
    "        reviews.append(review_text)\n",
    "\n",
    "    return reviews\n",
    "\n",
    "# Save the dummy dataset to a file\n",
    "dummy_reviews = generate_film_reviews()\n",
    "dataset_path = \"film_reviews_dataset.txt\"\n",
    "\n",
    "with open(dataset_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.writelines(dummy_reviews)\n",
    "\n",
    "print(f\"Dummy dataset saved to {dataset_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7248d2a-57ff-4cfa-86ba-cdbf88375368",
   "metadata": {},
   "source": [
    "# Train dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fdc4844-589c-4b48-868a-754db3b41f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepanshu.kandpal/Library/Caches/pypoetry/virtualenvs/llm-r-8tQ7me-py3.9/lib/python3.9/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/21 01:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./film_reviews_fine_tuned_v2/tokenizer_config.json',\n",
       " './film_reviews_fine_tuned_v2/special_tokens_map.json',\n",
       " './film_reviews_fine_tuned_v2/vocab.json',\n",
       " './film_reviews_fine_tuned_v2/merges.txt',\n",
       " './film_reviews_fine_tuned_v2/added_tokens.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Load your custom film reviews dataset\n",
    "dataset_path = \"./movie_reviews_dataset/reviews_1.txt\"\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=dataset_path,\n",
    "    block_size=128,  # Adjust the block size according to your dataset\n",
    ")\n",
    "\n",
    "# Use the default data collator for language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./film_reviews_fine_tuned_v2\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./film_reviews_fine_tuned_v2\")\n",
    "tokenizer.save_pretrained(\"./film_reviews_fine_tuned_v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58cd112-3b1d-4f85-af5b-7dd99995c3e6",
   "metadata": {},
   "source": [
    "# Prediction : Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07692190-acd5-4e0c-9a5b-db9e84647d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Film Review:\n",
      "The movie I watched yesterday was as a kid I remember feeling like what a scene it was yeah now you know it has\n",
      "become a huge success at the box office yeah yeah we are seeing a little bit of this so what draws you to this\n",
      "flawed hero uh you were attracted to that because um what I figured out even\n",
      "this this question I asked myself also what I figured out from the childhood\n",
      "whatever films I liked were all flawed man I don't know for some reason can can\n",
      "you name a couple of films that you like IND Chu Kam shatru is not a flawed man Wes character he's a little angry young\n",
      "man there's a lot actually in Hindi to there's a lot in English to there's a lot\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"dkandpalz/animalGPT2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dkandpalz/animalGPT2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"dkandpalz/animalGPT2\")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define a text generation pipeline\n",
    "text_generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Prompt for text generation\n",
    "prompt = \"The movie I watched yesterday was\"\n",
    "\n",
    "# Generate film review\n",
    "generated_review = text_generator(prompt, max_length=150, num_return_sequences=1, temperature=0.1)[0]['generated_text']\n",
    "\n",
    "# Print the generated review\n",
    "print(\"Generated Film Review:\")\n",
    "print(generated_review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70294fa3-583d-4afa-a147-440aa0511d90",
   "metadata": {},
   "source": [
    "# Prediction : Conversation Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a23ad-1630-42a0-b39a-c0efb714be7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Bot: Hi there! Let's talk about Animal. You can type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Who is Sandeep Reddy Vanga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Bot: Who is Sandeep Reddy Vanga Context: Sandep is an Indian film director, screenwriter and editor who makes Blockbuster free films. He is one of the highest-paid actors of Hindi cinema and has featured in Forbes India's Celebrity  list since. Kapoor is the recipient of several awards, including six Filmfare Awards. The son of actors Rishi Kapur and Neetu Singh, and the grandson of actor-director Raja Harish Chandra, Kapwin pursued filmmaking and method acting at the School of Visual Arts\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  which is your favourite scene from Animal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Bot: which is your favourite scene from Animal Park yet another great\n",
      "hug and papa that's the uh the first time we've seen a human being cut open by an ex it's fine\n",
      "you know that kind of stuff whoever wants to tell their story tells the story the way they want to\n",
      "tell it and uh while we're watching the film we always have this tendency of thinking what's in the market already so\n",
      "and um even when the hero Reveals His Name these are two very specific decisions that you've\n",
      "taken\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Give your Animal review\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Bot: Give your Animal review\n",
      "do something about it if you complain about the film then I can point to all the so to speak woke uh films that you have\n",
      "made and I could say why is this okay and why are you not doing this right and that's where we are at and we need to kind of view all\n",
      "of these films from the lens of unfortunately how they're going to be consumed by a society that anywh at this\n",
      "point of time believes that we have reached a point where this is no longer\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dkandpalz/animalGPT2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"dkandpalz/animalGPT2\")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define a text generation pipeline\n",
    "text_generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Start a conversation with the user\n",
    "print(\"Movie Bot: Hi there! Let's talk about Animal. You can type 'exit' to end the conversation.\")\n",
    "\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    # Check for exit condition\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Movie Bot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # Generate response\n",
    "    inputs = tokenizer(user_input, return_tensors=\"pt\")\n",
    "    generated_response = model.generate(**inputs, max_new_tokens=100, do_sample=True, top_p=0.92, top_k=0,num_beams=5,no_repeat_ngram_size=2,num_return_sequences=5,)\n",
    "    output = tokenizer.decode(generated_response[0], skip_special_tokens=True)\n",
    "    # Print the bot's response\n",
    "    print(\"Movie Bot:\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfd72fd-c75c-4232-ade4-f0550b5c192a",
   "metadata": {},
   "source": [
    "# POC 2 , SCRAPE DATA OF 2023 bollywood block busters (>200 cr box office)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dc1676f-fa15-4acc-8f16-e4e77e876c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import os\n",
    "\n",
    "# # Define a list of example URLs (replace these with your actual URLs)\n",
    "# example_urls = [\n",
    "#     'https://timesofindia.indiatimes.com/entertainment/hindi/movie-reviews/animal/movie-review/105651233.cms',\n",
    "#     'https://www.theguardian.com/film/2023/dec/02/animal-review-ranbir-kapoor-plays-one-of-the-vilest-protagonists-in-cinema-history',\n",
    "#     # Add more URLs as needed\n",
    "# ]\n",
    "\n",
    "# # Create a directory to store the scraped data\n",
    "# output_directory = 'movie_reviews_dataset'\n",
    "# os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# def scrape_movie_reviews(url):\n",
    "#     # Fetch the web page content\n",
    "#     response = requests.get(url)\n",
    "\n",
    "#     if response.status_code == 200:\n",
    "#         # Parse the HTML content\n",
    "#         soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#         # Extract movie reviews (modify based on the website structure)\n",
    "#         reviews = []\n",
    "#         review_elements = soup.find_all('div', class_='section1')  # Adjust based on HTML structure\n",
    "        \n",
    "#         # soup = BeautifulSoup(review_elements, 'html.parser')\n",
    "#         # Extract all text from the HTML\n",
    "#         print(review_elements)\n",
    "#         review_text = soup.get_text()\n",
    "#         reviews.append(review_text)\n",
    "#         # for review_element in review_elements:\n",
    "#         #     review_text = review_element.find('p', class_='Review:').text  # Adjust based on HTML structure\n",
    "#         #     reviews.append(review_text)\n",
    "\n",
    "#         return reviews\n",
    "#     else:\n",
    "#         print(f\"Failed to fetch the page. Status code: {response.status_code}\")\n",
    "#         return None\n",
    "\n",
    "# # Iterate through each URL and scrape reviews\n",
    "# for i, url in enumerate(example_urls, start=1):\n",
    "#     print(f\"Scraping data from {url}...\")\n",
    "\n",
    "#     movie_reviews = scrape_movie_reviews(url)\n",
    "\n",
    "#     if movie_reviews:\n",
    "#         # Save reviews to a text file\n",
    "#         output_file_path = os.path.join(output_directory, f'reviews_{i}.txt')\n",
    "\n",
    "#         with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "#             for review in movie_reviews:\n",
    "#                 file.write(review + '\\n')\n",
    "\n",
    "#         print(f\"Reviews saved to {output_file_path}\\n\")\n",
    "#     else:\n",
    "#         print(\"Skipping...\\n\")\n",
    "\n",
    "# print(\"Scraping complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95655a4-4d19-4aee-ac4f-90ef025e01fc",
   "metadata": {},
   "source": [
    "# DIALOGPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b0dcdc1-ecec-413d-9646-23ce2e0c64ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.0/26.0 [00:00<00:00, 2.93kB/s]\n",
      "config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 642/642 [00:00<00:00, 286kB/s]\n",
      "vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04M/1.04M [00:00<00:00, 1.18MB/s]\n",
      "merges.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 774kB/s]\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.75G/1.75G [02:33<00:00, 11.4MB/s]\n",
      "generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 124/124 [00:00<00:00, 19.6kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-large\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-large\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36ecb3ab-41e9-4368-82e3-38cdd7a12abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> User: hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: hi\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> User: what are you good at\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: i can play guitar\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> User: do you know about animal movie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: i do\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> User: what is the story\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: i have no idea\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> User: awesome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: i am glad\n"
     ]
    }
   ],
   "source": [
    "# Let's chat for 5 lines\n",
    "for step in range(5):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c74de46-8959-4f68-9438-10e77baefdac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
